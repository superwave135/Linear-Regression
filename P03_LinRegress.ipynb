{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from time import perf_counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_cols = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "raw_df = pd.read_csv(\"housing.data\", names = name_cols, header=None, delim_whitespace = True)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM       0\n",
      "ZN         0\n",
      "INDUS      0\n",
      "CHAS       0\n",
      "NOX        0\n",
      "RM         0\n",
      "AGE        0\n",
      "DIS        0\n",
      "RAD        0\n",
      "TAX        0\n",
      "PTRATIO    0\n",
      "B          0\n",
      "LSTAT      0\n",
      "MEDV       0\n",
      "dtype: int64\n",
      "Number of rows/datapoints: 506\n",
      "Number of columns/features: 14\n"
     ]
    }
   ],
   "source": [
    "print(raw_df.isnull().sum() ) # check for null values\n",
    "row_num = raw_df.shape[0]\n",
    "col_num = raw_df.shape[1]\n",
    "print(f'Number of rows/datapoints: {row_num}')\n",
    "print(f'Number of columns/features: {col_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last row last column: 11.9, type: <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(raw_df).to_numpy() # convert from dataframe format to numpy format\n",
    "print(f'last row last column: {df[505][-1]}, type: {type(df[1][-1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_input shape (506, 13)\n",
      "(506,)\n",
      "[4.741e-02 0.000e+00 1.193e+01 0.000e+00 5.730e-01 6.030e+00 8.080e+01\n",
      " 2.505e+00 1.000e+00 2.730e+02 2.100e+01 3.969e+02 7.880e+00]\n",
      "[19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9 22. ]\n"
     ]
    }
   ],
   "source": [
    "x_features_only = df[:, :-1]  # all features\n",
    "y_target = df[:, -1]  # only y label\n",
    "print('x_input shape', x_features_only.shape)\n",
    "print(y_target.shape)\n",
    "print(x_features_only[-1])\n",
    "print(y_target[-10:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "[[0.00000000e+00 1.80000000e-01 6.78152493e-02 ... 2.87234043e-01\n",
      "  1.00000000e+00 8.96799117e-02]\n",
      " [2.35922539e-04 0.00000000e+00 2.42302053e-01 ... 5.53191489e-01\n",
      "  1.00000000e+00 2.04470199e-01]\n",
      " [2.35697744e-04 0.00000000e+00 2.42302053e-01 ... 5.53191489e-01\n",
      "  9.89737254e-01 6.34657837e-02]\n",
      " ...\n",
      " [6.11892474e-04 0.00000000e+00 4.20454545e-01 ... 8.93617021e-01\n",
      "  1.00000000e+00 1.07891832e-01]\n",
      " [1.16072990e-03 0.00000000e+00 4.20454545e-01 ... 8.93617021e-01\n",
      "  9.91300620e-01 1.31070640e-01]\n",
      " [4.61841693e-04 0.00000000e+00 4.20454545e-01 ... 8.93617021e-01\n",
      "  1.00000000e+00 1.69701987e-01]]\n"
     ]
    }
   ],
   "source": [
    "def dataNorm(X):\n",
    "\n",
    "    xMerged = X[:,-1].T #output col. switch it's column to a row for vstack later   \n",
    "    f_transpose = X.T #feature cols. switch the columns to rows for iteration later\n",
    "    \n",
    "    for i in f_transpose:  \n",
    "        arr_transpose = (i - np.min(i)) / np.ptp(i)\n",
    "        xMerged = np.vstack((xMerged, arr_transpose))\n",
    "#     print(xMerged)    \n",
    "#     y_output = xMerged[0] # a row of 'Rings' data points\n",
    "#     final_merged = np.vstack((xMerged[1:], y_output)) # vstack the 8 features and the output at the bottom of the stack \n",
    "    final_merged = xMerged[1:]\n",
    "    return final_merged.T \n",
    "    \n",
    "x_features_only = dataNorm(x_features_only)\n",
    "print(x_features_only.shape)\n",
    "print(x_features_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n",
      "(506, 1)\n",
      "[4.61841693e-04 0.00000000e+00 4.20454545e-01 0.00000000e+00\n",
      " 3.86831276e-01 4.73079134e-01 8.02265705e-01 1.25071611e-01\n",
      " 0.00000000e+00 1.64122137e-01 8.93617021e-01 1.00000000e+00\n",
      " 1.69701987e-01 1.19000000e+01]\n",
      "(506, 14)\n"
     ]
    }
   ],
   "source": [
    "# test unit for joining the x_input and y_target back together\n",
    "\n",
    "print(y_target.shape)\n",
    "y_response = y_target.reshape((506,1)) # gotta reshape for concatenate purpose\n",
    "print(y_response.shape)\n",
    "x_features_y_response = np.concatenate((x_features_only, y_response), axis=1) # normalised features + y_label\n",
    "print(x_features_y_response[-1])\n",
    "print(x_features_y_response.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.80000000e-01 6.78152493e-02 ... 1.00000000e+00\n",
      "  8.96799117e-02 1.00000000e+00]\n",
      " [2.35922539e-04 0.00000000e+00 2.42302053e-01 ... 1.00000000e+00\n",
      "  2.04470199e-01 1.00000000e+00]\n",
      " [2.35697744e-04 0.00000000e+00 2.42302053e-01 ... 9.89737254e-01\n",
      "  6.34657837e-02 1.00000000e+00]\n",
      " ...\n",
      " [6.11892474e-04 0.00000000e+00 4.20454545e-01 ... 1.00000000e+00\n",
      "  1.07891832e-01 1.00000000e+00]\n",
      " [1.16072990e-03 0.00000000e+00 4.20454545e-01 ... 9.91300620e-01\n",
      "  1.31070640e-01 1.00000000e+00]\n",
      " [4.61841693e-04 0.00000000e+00 4.20454545e-01 ... 1.00000000e+00\n",
      "  1.69701987e-01 1.00000000e+00]]\n",
      "(506, 14)\n"
     ]
    }
   ],
   "source": [
    "# concat an all-ones col to x_input features (for y-intercept computation)\n",
    "# x_in is for gradient descent computation\n",
    "\n",
    "x_features_ones = np.concatenate([x_features_only, np.ones([np.shape(x_features_only)[0], 1])], axis=1)\n",
    "print(x_features_ones)\n",
    "print(x_features_ones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.00000000e+00, 1.80000000e-01, 6.78152493e-02, ...,\n",
      "        8.96799117e-02, 1.00000000e+00, 2.40000000e+01],\n",
      "       [2.35922539e-04, 0.00000000e+00, 2.42302053e-01, ...,\n",
      "        2.04470199e-01, 1.00000000e+00, 2.16000000e+01],\n",
      "       [2.35697744e-04, 0.00000000e+00, 2.42302053e-01, ...,\n",
      "        6.34657837e-02, 1.00000000e+00, 3.47000000e+01],\n",
      "       ...,\n",
      "       [6.11892474e-04, 0.00000000e+00, 4.20454545e-01, ...,\n",
      "        1.07891832e-01, 1.00000000e+00, 2.39000000e+01],\n",
      "       [1.16072990e-03, 0.00000000e+00, 4.20454545e-01, ...,\n",
      "        1.31070640e-01, 1.00000000e+00, 2.20000000e+01],\n",
      "       [4.61841693e-04, 0.00000000e+00, 4.20454545e-01, ...,\n",
      "        1.69701987e-01, 1.00000000e+00, 1.19000000e+01]])\n",
      "(506, 15)\n"
     ]
    }
   ],
   "source": [
    "# concat an all-ones col to x_input features (for y-intercept computation)\n",
    "# x_in is for gradient descent computation\n",
    "import pprint as pp\n",
    "x_features_ones_ylabel = np.concatenate([x_features_only, np.ones([np.shape(x_features_only)[0], 1]), y_response], axis=1)\n",
    "pp.pprint(x_features_ones_ylabel)\n",
    "print(x_features_ones_ylabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unit test\n",
    "y_out = x_features_ones_ylabel[:, -1]\n",
    "y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.60975755,   4.64204584,   0.56083933,   2.68673382,\n",
       "        -8.63457306,  19.88368651,   0.06721501, -16.22666104,\n",
       "         7.03913802,  -6.46332721,  -8.95582398,   3.69282735,\n",
       "       -19.01724361,  26.62026758])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In real life we don't want to code it directly\n",
    "np.linalg.lstsq(x_features_ones, y_target, rcond=None)[0] # the last in the output is the y-intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "def gradient_func(weights, X, y_target):  # Vectorized gradient function\n",
    "    '''\n",
    "    Given `weights` - a current \"Guess\" of what our weights should be\n",
    "          `X` - matrix of shape (N,D) of input features\n",
    "          `y_target` - target y values\n",
    "    Return gradient of each weight evaluated at the current value\n",
    "    '''\n",
    "    N, D = np.shape(X)\n",
    "    y_pred = np.dot(X, weights)  # alternative, use np.matmul()\n",
    "    error = np.subtract(y_pred, y_target)\n",
    "    return y_pred, error  # return the gradient of the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test, y_test, w):\n",
    "# def rmse_func(X, y_target, alpha):\n",
    "    '''\n",
    "    Given `X` - matrix of shape (N,D) of input features\n",
    "          `t` - target y values\n",
    "    Solves for linear regression weights.\n",
    "    Return weights after `niter` iterations.\n",
    "    '''\n",
    "#     N, D = np.shape(X)                                  # feature matrix has N rows and D cols\n",
    "#     w = np.zeros([D])                                   # initialize all the weights to zeros based on N cols of feature matrix\n",
    "    y_pred, error = gradient_func(w, x_test, y_test)   # call the gradient function. get y_pred, error output\n",
    "    print('y_pred shape:', y_pred.shape)\n",
    "#     print('error:', error)\n",
    "    \n",
    "    rmse = np.sqrt(np.square(np.subtract(y_test,y_pred)).mean()) \n",
    "    print('rmse:', rmse)\n",
    "    return y_pred, rmse  # return the gradient of the cost function\n",
    "\n",
    "#     for k in range(100000):   # loop over niter counts\n",
    "       \n",
    "#         y_pred, error = gradient_func(w, X, y_target)   # call the gradient function. get y_pred, error output\n",
    "#         dw = np.dot(np.transpose(X), error) / float(N)\n",
    "#         # -------------------------------------------------------------------------------\n",
    "#         prev = w                           # assign the previous weight to prev variable\n",
    "#         w = w - alpha * dw                 # update the weight with the learning rate and gradient change \n",
    "#         new = w                            # update the new weight to new variable\n",
    "#         # ------------------------------------------------------------------------------ \n",
    "#         MSE = np.square(np.subtract(y_target,y_pred)).mean() \n",
    "#     return np.sqrt(MSE), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "def gradient_descent(X, y_target, alpha, print_every=5000, niter=100000):  # gotta varies the alpha to get the most accurate w\n",
    "    '''\n",
    "    Given `X` - matrix of shape (N,D) of input features\n",
    "          `t` - target y values\n",
    "    Solves for linear regression weights.\n",
    "    Return weights after `niter` iterations.\n",
    "    '''\n",
    "    N, D = np.shape(X)                                  # feature matrix has N rows and D cols\n",
    "    w = np.zeros([D])                                   # initialize all the weights to zeros based on N cols of feature matrix\n",
    "    for k in range(niter):   # loop over niter counts\n",
    "       \n",
    "        y_pred, error = gradient_func(w, X, y_target)        # call the gradient function. get y_pred, error output\n",
    "        dw = np.dot(np.transpose(X), error) / float(N)\n",
    "        # -------------------------------------------------------------------------------\n",
    "        prev = w                           # assign the previous weight to prev variable\n",
    "        w = w - alpha * dw                 # update the weight with the learning rate and gradient change \n",
    "        new = w                            # update the new weight to new variable\n",
    "        # ------------------------------------------------------------------------------        \n",
    "        if k % print_every == 0:           # for every 5000 count\n",
    "            if np.all(new-prev) == False:  # when there is no improvement over the previous w, then get the latest optimal value\n",
    "                print(f\"Learning rate (alpha) is: {str(alpha)}\")\n",
    "                print(f'Weight after {k} iteration:\\n {str(w)}')\n",
    "                print()\n",
    "                break                 \n",
    "            elif k == 95000:\n",
    "                print()\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in progress ...\n",
      "\n",
      "Running in progress ...\n",
      "\n",
      "Running in progress ...\n",
      "\n",
      "Running in progress ...\n",
      "\n",
      "Running in progress ...\n",
      "\n",
      "Running in progress ...\n",
      "Learning rate (alpha) is: 0.5\n",
      "Weight after 15000 iteration:\n",
      " [ -9.60975755   4.64204584   0.56083933   2.68673382  -8.63457306\n",
      "  19.88368651   0.06721501 -16.22666104   7.03913802  -6.46332721\n",
      "  -8.95582398   3.69282735 -19.01724361  26.62026758]\n",
      "\n",
      "Running in progress ...\n",
      "Learning rate (alpha) is: 0.4\n",
      "Weight after 20000 iteration:\n",
      " [ -9.60975755   4.64204584   0.56083933   2.68673382  -8.63457306\n",
      "  19.88368651   0.06721501 -16.22666104   7.03913802  -6.46332721\n",
      "  -8.95582398   3.69282735 -19.01724361  26.62026758]\n",
      "\n",
      "Running in progress ...\n",
      "Learning rate (alpha) is: 0.3\n",
      "Weight after 25000 iteration:\n",
      " [ -9.60975755   4.64204584   0.56083933   2.68673382  -8.63457306\n",
      "  19.88368651   0.06721501 -16.22666104   7.03913802  -6.46332721\n",
      "  -8.95582398   3.69282735 -19.01724361  26.62026758]\n",
      "\n",
      "Running in progress ...\n",
      "Learning rate (alpha) is: 0.2\n",
      "Weight after 35000 iteration:\n",
      " [ -9.60975755   4.64204584   0.56083933   2.68673382  -8.63457306\n",
      "  19.88368651   0.06721501 -16.22666104   7.03913802  -6.46332721\n",
      "  -8.95582398   3.69282735 -19.01724361  26.62026758]\n",
      "\n",
      "Running in progress ...\n",
      "Learning rate (alpha) is: 0.1\n",
      "Weight after 70000 iteration:\n",
      " [ -9.60975755   4.64204584   0.56083933   2.68673382  -8.63457306\n",
      "  19.88368651   0.06721501 -16.22666104   7.03913802  -6.46332721\n",
      "  -8.95582398   3.69282735 -19.01724361  26.62026758]\n",
      "\n",
      "Running completed.\n",
      "The optimal weights:\n",
      " [ -9.60975755   4.64204584   0.56083933   2.68673382  -8.63457306\n",
      "  19.88368651   0.06721501 -16.22666104   7.03913802  -6.46332721\n",
      "  -8.95582398   3.69282735 -19.01724361  26.62026758]\n"
     ]
    }
   ],
   "source": [
    "# Part 5\n",
    "for i in np.arange(1.0, 0.0, -0.1):  # Part 5 main calling block\n",
    "    print('Running in progress ...')\n",
    "    w = gradient_descent(X = x_features_ones, y_target = y_target, alpha = round(i,3))\n",
    "print('Running completed.')\n",
    "# print('The first learning rate that shows up is the optimal learning rate.\\n')\n",
    "print('The optimal weights:\\n', w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 6\n",
    "for i in np.arange(1.0, 0.0, -0.1):  # Part 6 main calling block\n",
    "#     alpha = round(i, 3)\n",
    "    print('Running in progress ...')\n",
    "    rmse, y_pred = rmse_func(X= x_features_ones, y_target = y_target, alpha = round(i,3))\n",
    "print('Running completed.')\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 6\n",
    "def splitCV(X_norm, K): # Split a dataset into k folds\n",
    "    dataset_split = []\n",
    "    np.random.shuffle(X_norm) # shuffles the rows in the X_norm matrix\n",
    "    fold_size = int(len(X_norm) / K) # compute the num of rows per fold\n",
    "    row_num = X_norm.shape[0]\n",
    "\n",
    "    for i in range(K):\n",
    "        if i == K-1:\n",
    "            fold = np.array(X_norm)\n",
    "            dataset_split.append(X_norm)\n",
    "        else:\n",
    "            dataset_split.append(X_norm[:fold_size])\n",
    "            X_norm = X_norm[fold_size:]       \n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 6\n",
    "def CV_Main(x_features_ones_ylabel, cv_num): # k = number of neighbors\n",
    "    cv_list = []\n",
    "    X_cv = splitCV(x_features_ones_ylabel, cv_num) # split the data set into K folds = number of parts. X_cv is a list of folds\n",
    "    print('\\nCV_computation ongoing ... ')\n",
    "    for idx, list_array in enumerate(X_cv): # looping the dataset for cross validation \n",
    "        duplicate = X_cv.copy()\n",
    "        test = list_array\n",
    "        del duplicate[idx]  # delete the test element from duplicate set, remaining become train elements\n",
    "        train = duplicate   # remaining elements in duplicate become train set\n",
    "        train = np.vstack((train)) # convert train stack up vertically\n",
    "        cv_list.append(np.array([test, train])) #append test and train into a list before return\n",
    "    return cv_list  # cv_list is a list type containing 2 elements - test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV_computation ongoing ... \n",
      "-------- CV 5 --------\n",
      "y_pred shape: (101,)\n",
      "rmse: 4.952211774052191\n",
      "y_pred shape: (101,)\n",
      "rmse: 4.660991931276736\n",
      "y_pred shape: (101,)\n",
      "rmse: 6.282746928741\n",
      "y_pred shape: (101,)\n",
      "rmse: 4.750666925642314\n",
      "y_pred shape: (102,)\n",
      "rmse: 3.7240153273459575\n",
      "\n",
      "Elapsed time taken 6.258441300000015 seconds\n",
      "\n",
      "\n",
      "CV_computation ongoing ... \n",
      "-------- CV 10 --------\n",
      "y_pred shape: (50,)\n",
      "rmse: 5.395895658229513\n",
      "y_pred shape: (50,)\n",
      "rmse: 5.683511187073164\n",
      "y_pred shape: (50,)\n",
      "rmse: 5.057686082116991\n",
      "y_pred shape: (50,)\n",
      "rmse: 6.0713993869579665\n",
      "y_pred shape: (50,)\n",
      "rmse: 4.1333042505262245\n",
      "y_pred shape: (50,)\n",
      "rmse: 5.539359774793061\n",
      "y_pred shape: (50,)\n",
      "rmse: 4.978180487040395\n",
      "y_pred shape: (50,)\n",
      "rmse: 3.6018777038374465\n",
      "y_pred shape: (50,)\n",
      "rmse: 4.387777879064978\n",
      "y_pred shape: (56,)\n",
      "rmse: 3.6725627043071443\n",
      "\n",
      "Elapsed time taken 12.188356900000002 seconds\n",
      "\n",
      "\n",
      "CV_computation ongoing ... \n",
      "-------- CV 15 --------\n",
      "y_pred shape: (33,)\n",
      "rmse: 3.6662690364025763\n",
      "y_pred shape: (33,)\n",
      "rmse: 5.3326725064626554\n",
      "y_pred shape: (33,)\n",
      "rmse: 4.020304061229992\n",
      "y_pred shape: (33,)\n",
      "rmse: 3.882273040943749\n",
      "y_pred shape: (33,)\n",
      "rmse: 6.229179541010843\n",
      "y_pred shape: (33,)\n",
      "rmse: 5.749324749690674\n",
      "y_pred shape: (33,)\n",
      "rmse: 4.251641167926493\n",
      "y_pred shape: (33,)\n",
      "rmse: 4.158996297347994\n",
      "y_pred shape: (33,)\n",
      "rmse: 3.8337314561418183\n",
      "y_pred shape: (33,)\n",
      "rmse: 3.1551062179072495\n",
      "y_pred shape: (33,)\n",
      "rmse: 6.092216044098343\n",
      "y_pred shape: (33,)\n",
      "rmse: 3.8607417402103232\n",
      "y_pred shape: (33,)\n",
      "rmse: 4.400140677954357\n",
      "y_pred shape: (33,)\n",
      "rmse: 6.517400216222682\n",
      "y_pred shape: (44,)\n",
      "rmse: 6.097089324835662\n",
      "\n",
      "Elapsed time taken 18.736363299999994 seconds\n",
      "\n",
      "\n",
      "---- Run completed ----\n"
     ]
    }
   ],
   "source": [
    "## for-loop block code to call the knnCV_Main to perform cross validation \n",
    "def main(): \n",
    "\n",
    "    \n",
    "    # MAIN CALL BLOCK for CROSS VALIDATION over 5, 10, 15\n",
    "    for cv in [5,10, 15]:  # Looping over the cv numbers\n",
    "\n",
    "        cv5_list = []   # got 2 elements. [0] stores y_pred. [1] stores rmse \n",
    "        cv10_list = []  # got 2 elements. [0] stores y_pred. [1] stores rmse\n",
    "        cv15_list = []  # got 2 elements. [0] stores y_pred. [1] stores rmse\n",
    "\n",
    "        t1_start = perf_counter() # Start the stopwatch / counter \n",
    "        cv_list = CV_Main(x_features_ones_ylabel, cv)\n",
    "        print(f\"-------- CV {cv} --------\")\n",
    "\n",
    "        for num in cv_list:\n",
    "\n",
    "            test = num[0]\n",
    "            x_test = test[:, :-1]\n",
    "            y_test = test[:, -1]\n",
    "\n",
    "            train = num[1]\n",
    "            x_train = train[:, :-1]\n",
    "            y_train = train[:, -1]\n",
    "\n",
    "            w = gradient_descent(x_train, y_train, alpha=0.5)  # get the fitted weights from x, y train sets \n",
    "            y_pred, rmse = predict(x_test, y_test, w)          # apply the w onto the x, y test sets to yield y_pred \n",
    "\n",
    "            if cv == 5:\n",
    "                cv5_list.append(y_pred)\n",
    "                cv5_list.append(rmse) \n",
    "            elif cv == 10:\n",
    "                cv10_list.append(y_pred)\n",
    "                cv10_list.append(rmse)\n",
    "            elif cv == 15:\n",
    "                cv15_list.append(y_pred)\n",
    "                cv15_list.append(rmse)\n",
    "\n",
    "            # GRAB the y_pred to OUPUT folder ...\n",
    "            # GRAB the rmse to DATA folder  ...\n",
    "\n",
    "        t1_stop = perf_counter() # Stop the stopwatch / counter \n",
    "        print(f'\\nElapsed time taken {t1_stop-t1_start} seconds\\n') \n",
    "    print()\n",
    "    print('---- Run completed ----')    \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dataStandard(X):\n",
    "\n",
    "#     xMerged = X[:,-1].T #output col. switch it's column to a row for vstack later   \n",
    "#     f_transpose = X[:, :-1].T #feature cols. switch the columns to rows for iteration later\n",
    "    \n",
    "#     for i in f_transpose:  \n",
    "#         arr_transpose = (i - np.average(i)) / np.std(i)\n",
    "#         xMerged = np.vstack((xMerged, arr_transpose))\n",
    "        \n",
    "#     y_output = xMerged[0] # a row of 'Rings' data points\n",
    "#     final_merged = np.vstack((xMerged[1:], y_output)) # vstack the 8 features and the output at the bottom of the stack \n",
    "#     return final_merged.T \n",
    "    \n",
    "# X_norm = dataStandard(X)\n",
    "# print(X_norm.shape)\n",
    "# print(len(X_norm))\n",
    "# X_norm[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
